{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** This notebook has two parts: ***\n",
    "    \n",
    "*** 1) a VERY long explanation of Gibss sampling ***\n",
    "   \n",
    "*** 2) Implementation of the Gibbs sampling for a linear model! ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*** PART 1 ***\n",
    "\n",
    "Using the idea of Markov Chain and the fact that Markov chain will converge to a steady state. We can build a Monte Carlo process for sampling from a distribuition. Here, we talk about the Gibbs sampling method aa is one of the (Markov Chain Monte Carlo) MCMC methods. \n",
    "We assume we have a distribution of form $P(x_{1}, x_{2}, x_{3})$. Steps we take are listed below, \n",
    "\n",
    "1) Start with initial values ($x_{1}^{0}, x_{2}^{0}, x_{3}^{0}$)\n",
    "\n",
    "2) At each iteration we update one dimention at a time:\n",
    "\n",
    "\n",
    "$x_{1}^{1} \\longrightarrow P(x_{1}| x_{2}^{0}, x_{3}^{0})$\n",
    "\n",
    "$x_{2}^{1} \\longrightarrow P(x_{2}| x_{1}^{1}, x_{3}^{0})$\n",
    "\n",
    "$x_{3}^{1} \\longrightarrow P(x_{3}| x_{1}^{1}, x_{2}^{1})$\n",
    "\n",
    "\n",
    "\n",
    "3) Repeat for $k = 1 ... n$ times so we get: \n",
    "\n",
    "\n",
    "$x_{1}^{k+1} \\longrightarrow P(x_{1}| x_{2}^{k}, x_{3}^{k})$\n",
    "$x_{2}^{k+1} \\longrightarrow P(x_{2}| x_{1}^{k+1}, x_{3}^{k})$\n",
    "$x_{3}^{k+1} \\longrightarrow P(x_{3}| x_{1}^{k+1}, x_{2}^{k+1})$\n",
    "\n",
    "\n",
    "So, each step depends on the previus steps and cannot be done in parallel. \n",
    "\n",
    "But, why Gibss sampling work? Here is a short proof:\n",
    "\n",
    "So the idea is that we want to implement the markov chain property that (under some loose conditions) the chain will converge to a steady state. We assume that the distribution we want to sample from is a steady state of a markov chain. And we introduce $q(x,y,z)$ as a transition matrix. So, for Gibss sampling we want to prove : \n",
    "\n",
    "$p(x',y',z') = \\sum_{x,y,z} q(x,y,z \\rightarrow x',y',z') p(x,y,z)$ \n",
    "\n",
    "$q(x,y,z)$ is a conditional probabilty (following Gibss rules), so we can rewrite the bove equation as follows:\n",
    "\n",
    "$\\sum_{x,y,z} q(x,y,z \\rightarrow x',y',z') p(x,y,z) = \\sum_{x,y,z} p(x'|y= y, z=z) p(y'|x= x', z=z) p(z'|x= x', y=y') p(x,y,z)$\n",
    "\n",
    "The equation can be simplified by bringing the $p(z'|x',y')$ term out of summation as it does not depond on x, y, z any more. \n",
    "\n",
    "$\\sum_{x,y,z} p(x'|y= y, z=z) p(y'|x= x', z=z) p(z'|x= x', y=y') p(x,y,z) = p(z'|x',y')\\sum_{x,y,z} p(x'|y, z) p(y'|x', z)  p(x,y,z) $\n",
    "\n",
    "As, $p(x'|y, z) p(y'|x', z)$ dont depend on x we can simplify the summation even more:\n",
    "\n",
    "$p(z'|x',y') \\sum_{x,y,z} p(x'|y, z) p(y'|x', z) p(x,y,z) = p(z'|x',y') \\left(\\sum_{y,z} p(x'|y, z) p(y'|x', z)\\sum_{x}p(x,y,z)\\right)$\n",
    "\n",
    "$\\sum_{x}p(x,y,z)$ is the margenalization for $x$ and can be written as:\n",
    "\n",
    "$\\sum_{x}p(x,y,z) = p(y,z)$\n",
    "\n",
    "So the euqation will be more simplified as:\n",
    "\n",
    "$ p(z'|x',y') \\left(\\sum_{y,z} p(x'|y, z) p(y'|x', z)\\sum_{x}p(x,y,z)\\right) = p(z'|x',y') \\sum_{y,z} p(x'|y, z) p(y'|x', z) p(y,z)$\n",
    "\n",
    "Here:\n",
    "\n",
    "$\\sum_{y,z} p(x'|y,z)p(y,z) = \\sum_{y,z} p(x',y,z) = \\sum_{z} p(x',z)$\n",
    "\n",
    "So the equation can be simplified as:\n",
    "\n",
    "$p(z'|x',y') \\sum_{y,z} p(x'|y, z) p(y'|x', z) p(y,z) = p(z'|x',y')\\sum_{z} p(y'|x', z) p(x',z)$\n",
    "\n",
    "With the same logic:\n",
    "\n",
    "$p(z'|x',y')\\sum_{z} p(y'|x', z) p(x',z) = p(z'|x',y')p(y',x') = p(x',y',z')$\n",
    "\n",
    "So we can see that:\n",
    "\n",
    "$p(x',y',z') = \\sum_{x,y,z} q(x,y,z \\rightarrow x',y',z') p(x,y,z)$\n",
    "\n",
    "\n",
    "Now knowing that Gibss sampling works we can have an example:\n",
    "\n",
    "We are looking at the linear regression problem in which we know x (input) and y (output) and we want to find slope and intercept. \n",
    "\n",
    "We have set of $(x_{i},y_{i})$ and we know : \n",
    "$y_{i} = \\beta_{1} x_{i} + \\beta_{0}$\n",
    "We want to find $\\beta_{1}$ and $\\beta_{0}$. We assume that the two parameters are following normal distribution and $y_{i}$ is following the normal distribution as well such that:\n",
    "\n",
    "($y_{i}|x_{i}, \\beta_{0}, \\beta_{1}, \\frac{1}{\\tau}) \\rightarrow N(\\beta_{0}+\\beta_{1} x_{i}, \\frac{1}{\\tau})$\n",
    "\n",
    "$\\beta_{0} \\rightarrow N(\\mu_{0}, \\frac{1}{\\tau_{0}})$\n",
    "\n",
    "$\\beta_{1} \\rightarrow N(\\mu_{1}, \\frac{1}{\\tau_{1}})$\n",
    "\n",
    " ***So, the posteriori for $\\beta_{0}$ can be calculates as follows:***\n",
    "\n",
    "\n",
    "1) the log dependence is written as:\n",
    "\n",
    "$-\\tau/2 \\sum_{i}(y_{i}-\\beta_{0}+\\beta_{1} x_{i})^2 - \\tau_{0}/2(\\beta_{0} - \\mu_{0})^2$\n",
    "\n",
    "where the first term is likelihood from the observations and the second term is the apriori term. \n",
    "\n",
    "2) We rearrange the equation to be solved for $\\beta_{0}$:\n",
    "\n",
    "$-\\frac{\\tau}{2} \\sum_{i}(y_{i}-\\beta_{0}+\\beta_{1} x_{i})^2 - \\frac{\\tau_0}{2}(\\beta_{0} - \\mu_{0})^2 = \n",
    "-\\frac{\\tau}{2} \\sum_{i} \\left ((y_{i}-\\beta_{1} x_{i})^2 -2(y_{i}-\\beta_{1}x_{i})\\beta_0\\right) + \\beta_{0}^2 - \\frac{\\tau_0}{2} (\\beta_0^2 - 2\\mu_0 \\beta_0 + \\beta_0^2)$\n",
    "\n",
    "3) Delet all terms which are not dependent to $\\beta_0$:\n",
    "\n",
    "$-\\frac{\\tau}{2} \\sum_{i} \\left ((y_{i}-\\beta_{1} x_{i})^2 -2(y_{i}-\\beta_{1}x_{i})\\beta_0\\right) + \\beta_{0}^2 - \\frac{\\tau_0}{2} (\\beta_0^2 - 2\\mu_0 \\beta_0 + \\beta_0^2) = \\tau \\sum_{i} \\left((y_{i}-\\beta_{1}x_{i})\\beta_0 \\right) - \\frac{\\tau}{2} N\\beta_0^2 + \\tau_0 \\mu_0 \\beta_0 + \\frac{\\tau_0}{2} \\beta_0^2 $\n",
    "\n",
    "4) As the expression is a quadratic function of {\\beta_0} the conditional sampling for $\\beta_0$ will be normal:\n",
    "\n",
    "$(\\beta_{0}|x_{i}, y_{i}, \\beta_{1}, \\tau, \\tau_1, \\tau_0) \\rightarrow N(\\frac{\\tau_0\\mu_0 + \\tau \\sum_{i}(y_i - \\beta_1 x_i)}{\\tau_0 + N \\tau},\\frac{1}{\\tau_0 + N \\tau} )$\n",
    "\n",
    "And we just need to sample from this last expression\n",
    "\n",
    "*** Similarly the posterior for $\\beta_1$ can be calculated ***:\n",
    "\n",
    "1) $\\frac{-\\tau}{2}\\sum_{i} (y_i - \\beta_0 -\\beta_1 x_i)^2 - \\frac{-\\tau_1}{2} (\\beta_1 - \\mu_1)^2 = \n",
    "\\frac{-\\tau}{2} \\sum_{i} \\left((y_i-\\beta_0)^2 + (\\beta_1 x_i)^2 - 2 \\beta_1 x_i(y_i - \\beta_0) \\right) - \\frac{-\\tau_1}{2} \\beta_1^2 + \\tau_1 \\mu_1 \\beta_1 - \\frac{-\\tau_1}{2} \\mu_1^2 $\n",
    "\n",
    "2) We only take the terms which depend on $\\beta_1$ and simplify the equation as follows:\n",
    "\n",
    "$\\frac{-\\tau}{2} \\sum_i \\beta_1^2 x_i^2 + \\tau \\sum_i (y_i - \\beta_0) x_i \\beta_1 - \\frac{-\\tau_1}{2} \\beta_1^2 + \\tau_1 \\mu_1 \\beta_1$\n",
    "\n",
    "3) So we can see the normal form with respect for $\\beta_1$ now:\n",
    "\n",
    "$\\beta_1 | \\beta_0 , \\tau, \\tau_1,\\mu_1, x, y = N \\left( \\frac{\\tau_1\\mu_1 + \\tau \\sum (y_i - \\beta_0) x_i}{\\tau_1 + tau \\sum x_i^2}, \\frac{1}{\\tau_1 + \\tau \\sum_i x_i^2}\\right)$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** PART 2 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_data():\n",
    "        beta_0_true = 2\n",
    "        beta_1_true = -1\n",
    "        tau_true = 2.3\n",
    "        x = np.random.uniform(0,5,100)\n",
    "        y = np.random.normal(beta_0_true + beta_1_true * x, 1 / np.sqrt(tau_true))\n",
    "        \n",
    "        return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_beta_0(y, x, beta_1, tau, mu_0, tau_0):\n",
    "    \n",
    "    mean_beta_0 = (tau_0 * mu_0 + tau * np.sum(y - beta_1 * x))/(tau_0 + tau * len(x))\n",
    "    p_beta_0 = tau_0 + tau * len(x)\n",
    "    beta_0_sample = np.random.normal(mean_beta_0, 1 / np.sqrt(p_beta_0))\n",
    "    \n",
    "    return beta_0_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_beta_1(y, x, beta_0, tau, mu_1, tau_1):\n",
    "   \n",
    "    \n",
    "    mean_beta_1 = (tau_1 * mu_1 + tau * np.sum( (y - beta_0) * x))/ (tau_1 + tau * np.sum(x * x))\n",
    "    p_beta_1 = tau_1 + tau * np.sum(x * x)\n",
    "    beta_1_sample = np.random.normal(mean_beta_1, 1 / np.sqrt(p_beta_1 ))\n",
    "    \n",
    "    return  beta_1_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gibbs_sampling():\n",
    "    x, y = make_fake_data()\n",
    "    beta_0 = 0\n",
    "    beta_1 = 0\n",
    "    mu_0 = 1\n",
    "    mu_1 = 1\n",
    "    tau_0 = 1\n",
    "    tau = 2\n",
    "    tau_1 = 1\n",
    "    iteration = 1500\n",
    "    beta_0_list = []\n",
    "    beta_1_list = []\n",
    "    for i in range(iteration):\n",
    "        beta_0 = sampler_beta_0(y, x, beta_1, tau, mu_0, tau_0)\n",
    "        beta_1 = sampler_beta_1(y, x, beta_0, tau, mu_1, tau_1)\n",
    "        beta_0_list.append(beta_0)\n",
    "        beta_1_list.append(beta_1)\n",
    "        \n",
    "\n",
    "        \n",
    "    return beta_0_list, beta_1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0_list, beta_1_list = linear_gibbs_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(beta_0_list, bins = 100)\n",
    "plt.xlim(1.2, 2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(beta_1_list, bins = 100)\n",
    "plt.xlim(-1.1, -.8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean for beta_1 is: -0.955333344033549\n",
      "the mean for beta_0 is: 1.9277667877225486\n",
      "the standard deviation for beta_1 is: 0.05585218838157741\n",
      "the standard deviation for beta_0 is: 0.1866843738346787\n"
     ]
    }
   ],
   "source": [
    "print('the mean for beta_1 is:',np.mean(beta_1_list))\n",
    "print('the mean for beta_0 is:',np.mean(beta_0_list))\n",
    "print('the standard deviation for beta_1 is:',np.std(beta_1_list))\n",
    "print('the standard deviation for beta_0 is:',np.std(beta_0_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
